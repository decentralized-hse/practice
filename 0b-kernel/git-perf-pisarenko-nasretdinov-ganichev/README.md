# Git как база данных: Анализ узких мест

**Авторы:** Писаренко Григорий @GrigPisar, Насретдинов Тимур @dffTuTG, Ганичев Василий @ganvas

## Задача

Многие менеджеры пакетов используют git в качестве базы данных, и многие об этом жалеют. Найдите узкие места и протестируйте их на реальных данных.

## 1. Введение

Git был спроектирован как распределенная система контроля версий, а не как база данных общего назначения. Однако многие менеджеры пакетов (npm, Go modules, Cargo, Homebrew и др.) полагаются на git-репозитории — либо напрямую, либо через API GitHub/GitLab — как на основное хранилище данных для метаданных пакетов, индексов версий и распространения исходного кода.

Такая практика приводит к появлению значительных узких мест в производительности по мере роста репозиториев. Этот документ выявляет эти узкие места, объясняет *почему* они возникают и предоставляет результаты тестов на реальных репозиториях для количественной оценки их влияния.

## 2. Выявленные узкие места

### 2.1 Клонирование / Первоначальная загрузка (O(кол-во коммитов))

**Проблема:** По умолчанию `git clone` передает *всю* историю репозитория. Для репозитория с индексом пакетов, содержащего сотни тысяч коммитов, это означает загрузку сотен мегабайт (или даже гигабайт) данных в packfile. Эта команда обязательна при настройке, поэтому проблема важна.

**Основная причина:** Packfile формат git хранит все объекты (коммиты, деревья, блобы), сжатые с использованием дельт относительно друг друга. Сервер должен перечислить все достижимые объекты, вычислить дельты и отправить их потоком. Клиент должен получить, проверить и проиндексировать их все.

**Масштабирование:** Время и трафик растут **линейно** пропорционально с количеством объектов в репозитории.

**Сравнение с БД:** Взаимодействие с обычной SQL-базой данных занимает O(необходимый объем данных) для получения информации.

### 2.2 Git Log / Обход истории (O(коммиты))

**Проблема:** Операции, такие как `git log`, `git log -- <путь>` или `git rev-list`, должны обходить граф коммитов. В репозитории с 500k+ коммитов это занимает секунды даже для простых запросов. Это необходимо для поиска даты последнего изменения и определения того, какие пакеты следует обновить, например, для Homebrew:

- `git log -1 -- <имя пакета>`

В обычной базе данных это можно сделать простым запросом с индексом по имени пакета, но в git это занимает время O(коммиты).

**Основная причина:** Git хранит коммиты в виде связного списка (направленного ациклического графа). Нет вторичных индексов по путям, датам или авторам. Каждый запрос требует линейного обхода цепочки коммитов, открытия и распаковки объектов из packfile'ов.

**Масштабирование:** Время растет **линейно** с количеством коммитов. Лог с фильтрацией по пути (`git log -- путь/к/файлу`) работает еще хуже, потому что git должен выполнить diff для *каждого* дерева коммита, чтобы определить, какие коммиты изменили файл.

### 2.3 Git Blame (O(коммиты x размер_файла))

**Проблема:** `git blame` прослеживает каждую строку файла до коммита, который последним изменил её. Для больших файлов с долгой историей это чрезвычайно затратно. Эта команда используется для безопасности/аудита, чтобы идентифицировать авторов конкретных пакетов, и может работать медленно по сравнению с обычными базами данных.

**Основная причина:** Blame проходит по истории коммитов в обратном порядке, выполняя построчный diff на каждом шаге. Сложность алгоритма примерно равна `O(коммиты x строки)` для одного файла.

**Масштабирование:** `git blame` для больших файлов в ядре Linux (например, `CREDITS`, `MAINTAINERS`) может занимать 30+ секунд. В репозитории индекса пакетов `git blame` для индексного файла может быть еще медленнее.

### 2.4 Перечисление ссылок (O(ссылки))

**Проблема:** `git ls-remote`, `git for-each-ref` и `git tag -l` перечисляют все ссылки (ветки + теги). В некоторых репозиториях накапливаются тысячи тегов (по одному на релиз). Обычно эта команда используется для вывода списка релизов перед каждой установкой или обновлением.

**Основная причина:** Каждая ссылка — это либо отдельный файл в `.git/refs/`, либо строка в `.git/packed-refs`. Их перечисление требует чтения всех записей. На сервере `ls-remote` заставляет сервер перечислить *все* ссылки *до* применения фильтрации.

**Масштабирование:** Линейно от количества ссылок. Для репозиториев со 100k+ тегов (например, crates.io-index) это добавляет заметную задержку.

### 2.5 Размер репозитория на диске (O(объекты))

**Проблема:** Даже после `git gc` и переупаковки большие репозитории занимают значительное дисковое пространство. Каталог `.git/objects/pack` может вырасти до нескольких гигабайт.

**Основная причина:** Git хранит *всю* историю локально. Дельта-компрессия помогает, но только до определенного предела. Большие бинарные файлы, частые изменения одних и тех же файлов и глубокая история — все это вносит свой вклад.

**Масштабирование:** Использование диска растет с общим количеством уникальных объектов. В CI-системах, где репозитории клонируются заново для каждой сборки, это усугубляется сетевыми издержками и издержками ввода-вывода.

## 3. Методология тестирования

Мы создали набор Python-скриптов, которые измеряют производительность ключевых операций git на реальных репозиториях. Скрипты:

1.  **Тесты клонирования** (`bench_clone.py`) — измеряют `git clone` с разными стратегиями (полный, поверхностный `--depth=1`, частичный `--filter=blob:none`)
2.  **Тесты лога** (`bench_log.py`) — измеряют `git log`, `git log --oneline`, `git log -- <путь>` и `git rev-list --count`
3.  **Тесты blame** (`bench_blame.py`) — измеряют `git blame` на файлах разного размера
4.  **Тесты ссылок** (`bench_refs.py`) — измеряют `git tag -l`, `git branch -a`, `git for-each-ref`, `git ls-remote`
5.  **Анализ размера репозитория** (`bench_repo_size.py`) — измеряют размер каталога `.git`, количество объектов, размер packfile, количество распакованных объектов
6.  **Генерация графиков** (`plot_results.py`) — читают все JSON-результаты и создают PNG-диаграммы

### Целевые репозитории

Тесты используют следующие реальные репозитории (настраивается):

| Репозиторий                 | Описание                    | Примерное кол-во коммитов |
|------------------------------|-----------------------------|---------------------------|
| `torvalds/linux`             | Ядро Linux                  | 1 400 000+                |
| `homebrew/homebrew-core`     | Формулы Homebrew            | 760 000+                  |
| `rust-lang/crates.io-index`  | Индекс пакетов Cargo        | 70 000+                  |

### Как запустить

```bash
pip install -r requirements.txt

python bench_clone.py
cd repos
git clone https://github.com/torvalds/linux.git
git clone https://github.com/Homebrew/homebrew-core.git
git clone https://github.com/rust-lang/crates.io-index.git
python bench_blame.py
python bench_log.py
python bench_refs.py
python bench_repo_size.py

python plot_results.py
```

## 4. Результаты и анализ

### 4.1 Производительность git clone

| Репозиторий      |  Full Clone (сек / размер / объекты) | Shallow Clone (s / sz / cnt)  | Partial Clone (s / sz / cnt) |
|-----------------|----------------------------------|-------------------------------|------------------------------|
| linux           | 325.82 / 5.8 GB / 11'378'599     | 22.82 / 273.14 MB / 98'475    | 161.62 / 1.66 GB / 8'305'301 |
| homebrew-core   | 195.92 / 1.04 GB / 3'248'860     | 3.31 / 10.65 MB / 8'873       | 118.09 / 814.35 MB / 2586977 |
| crates.io-index | 98.26 / 513.84 MiB / 838'185     | 165.73 / 208.22 MiB / 268'377 | 236.4 / 41.25 MiB / 353634   |

- Shallow clone самый быстрый тип клонирования.

**Вывод:** `git clone` является узким местом и занимает значительное время даже при стабильном и быстром интернет соединении 30-40 MB/s. `--depth=1` почти всегда радикально снижает стоимость старта, но может ломать сценарии, которым нужна история. `--filter=blob:none` уменьшает объём, но не скачивание и индексирование большого числа объектов, поэтому ускорение ограничено и сильно зависит от репозитория/сервера.

### 4.2 Производительность git log / git rev-list / git shortlog

| Репозиторий      |  git log -n 100 (сек) | git log -n 1000 (сек)  | git log -n 10000 (сек) |
|-----------------|----------------------------------|-------------------------------|------------------------------|
| linux           | 0.012 | 0.039 | 0.171 |
| homebrew-core   | 0.009 | 0.02 | 0.122 |
| crates.io-index | 0.007 | 0.013 | 0.082 |

| Репозиторий      |  git rev-list --count HEAD (сек) |
|-----------------|----------------------------------|
| linux           | 11.856 |
| homebrew-core   | 5.975 |
| crates.io-index | 0.308 |

| Репозиторий      |  git shortlog -sn --no-merges (сек) |
|-----------------|----------------------------------|
| linux           | 14.382 |
| homebrew-core   | 7.051 |
| crates.io-index | 0.357 |

**Вывод:** операции посчитать/просканировать историю (`rev-list --count`, `shortlog`, большие/фильтрованные `log`) быстро становятся дорогими на больших числах коммитов. 

### 4.3 Производительность git blame

| linux файлы     | Makefile | README | CREDITS | MAINTAINERS | kernel/fork.c | kernel/sched/core.c |
|-----------------|----------------------------------|-|-|-|-|-|
| Кол-во строк / секунды           | 2249 / 1.805 | 168 / 0.664 | 4558 / 1.414 | 29210 / 44.426 | 3311 / 2.199 | 10983 / 4.438 |

| homebrew-core файлы     | Formula/g/git.rb | Formula/w/wget.rb | Formula/p/python@3.12.rb |
|-----------------|----------------------------------|-|-|
| Кол-во строк / секунды           | 237 / 60.735 | 58 / 157.838 | 525 / 2.572 |

| crates.io-index файлы     | se/rd/serde | to/ki/tokio | ra/nd/rand |
|-----------------|----------------------------------|-|-|
| Кол-во строк / секунды           | 315 / 3.01 | 180 / 3.877 | 85 / 3.586 |

`git blame` - самая затратная операция на один файл.

**Вывод:** `git blame` — один из самых дорогих кандидатов для запросов в модели использования git как БД, так как время определяется одновременно размером файла и глубиной истории, и на живых больших репозиториях легко уходит в десятки секунд даже для относительно небольших файлов (что видно на homebrew-core).

### 4.4 Производительность git tag / git branch / git for-each-ref

| Репозиторий     | tag -l (refs cnt / sec) | branch -a | for-each-ref |
|-----------------|----------------------------------|-|-|
| linux           | 919 / 0.02 | 3 / 0.02 | 922 / 0.015 |
| homebrew-core  | 11 / 0.002 | 58 / 0.002 | 69 / 0.002 |
| crates.io-index  | 0 / 0.002 | 3 / 0.001 | 3 / 0.001 |

**Вывод:** перечисление ссылок (особенно тегов) само по себе обычно не работает быстро обычных репозиториях, но при десятках тысячах тегов превращается в заметную постоянную задержку, которая может быть заметна пользователю, если выполняется перед каждой операцией.

### 4.5 Размеры репозиториев

| Репозиторий      | Коммиты | Файлы | Теги | Ветки | .git (МБ) | Pack (МБ) | Общий вес (МБ) |
|------------------|-------------|-----------------|-----------------|-|-|-|-|
| linux            | 1.426.202     | 92.982   | 919         |3|6375|5945|7870|
| homebrew-core    | 760.547     | 8.744    | 11         |58|1170|1070|1197|
| crates.io-index  | 69.590     | 228.929    | 0         |3|559|514|3771|

**Вывод:** большой размер папки `.git` может значительно замедлять работу скачивания репозитория / работу CI (так как требуется перед запуском скачать репозиторий заново). Таким образом из-за того что размер зависит линейно от размера истории это является узким местом.

## 5. Выводы

### Итог: где git ломается как база данных

1. **Главная стоимость — скачать и инициализировать репозиторий, а не запросить данные.**  
   В БД вы платите за конкретный запрос; в git вы часто сначала платите за перенос и индексацию больших объёмов истории/объектов.

2. **Большинство запросов в git — это линейные обходы, а не обращения по индексу.**  
   Подсчёт коммитов, статистика авторов, поиск последнего изменения (особенно по пути) — всё это деградирует как O(n) по истории и начинает занимать большое количество времени.

3. **Некоторые операции принципиально плохо подходят для частого запуска (blame).**  
   `git blame` имеет двумерную стоимость (история × размер файла) и легко превращается в десятки секунд, то есть требует кэширования/предвычисления или отказа от использования в горячем пути.

4. **Метаданные релизов через refs масштабируются линейно и могут давать ощутимую задержку при большом числе тегов.**  
   Для каталогов пакетов с большим количеством релизов/тегов это становится заметным даже если каждая отдельная операция кажется небольшой.

5. **Практический вывод для менеджеров пакетов:**  
   Git хорош как механизм распространения исходников и контент-адресуемое хранилище, но плох как запросная БД метаданных. Если нужно быстро найти/отфильтровать/агрегировать, почти всегда выгоднее вынести метаданные в специализированное хранилище (SQL/Key-Value/поисковый индекс) и использовать git как транспорт/архив, а не как основной слой запросов.
